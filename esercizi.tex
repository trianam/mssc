
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

\documentclass[a4paper,twosides]{report}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{microtype}
\usepackage{acronym}
\usepackage[fleqn]{mathtools}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{xcolor}
%\usepackage[hidelinks,breaklinks=true]{hyperref}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage{pgfornament}
\usepackage{tikz}
\usepackage[fleqn]{amsmath}
\usepackage{mathpartir}
\usepackage{hyperref}

\newcommand{\betaReduction}{\ensuremath{\longrightarrow_{\beta}}}
\newcommand{\betaReductionS}{\ensuremath{\Longrightarrow_{\beta}}}

\newcommand{\sectionline}{
  \begin{center}
    \resizebox{0.5\linewidth}{5ex}{
      \hyperref[toc]{
        \begin{tikzpicture}
          \node  (C) at (0,0) {};
          \node (D) at (10,0) {};
          \path (C) to [ornament=84] (D);
        \end{tikzpicture}
      }
    }
  \end{center}
}

\newcommand\encircle[1]{%
  \tikz[baseline=(X.base)] 
    \node (X) [draw, shape=circle, inner sep=0] {\strut #1};}

\newcommand\enbox[1]{%
  \tikz[baseline=(X.base)] 
    \node (X) [draw, shape=rectangle, inner ysep=.2ex, inner xsep=.5em] {\strut #1};}

\author{
  {\Large Stefano Martina}\\
  {\small stefano.martina@stud.unifi.it}\\
  Universit\`a degli Studi di Firenze\\
  Scuola di Scienze Matematiche, Fisiche e Naturali\\
  Corso magistrale di Informatica
}
\title{{\Huge\bfseries Modelli di Sistemi Sequenziali e
    Concorrenti}\\{\large\bfseries esercizi}}

\begin{document}
\maketitle
\tableofcontents
\label{toc}
\newpage

\section*{\hyperref[toc]{Esercizio 3.15}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 3.15}
\subsection*{Testo:}
Dimostrare che, per ogni espressione aritmetica $E$ descritta nella
Sezione 3.3,
$$
E\ \rightarrow\ E_1,\ E\ \rightarrow\ E_2\quad \text{implica}\quad E_1\
\twoheadrightarrow\ n,\ E_2\ \twoheadrightarrow\ n
$$

\subsection*{Soluzione:}
\paragraph{Premessa:}Si noti che se vale la tesi, allora vale anche che $E\
\twoheadrightarrow\ n$, infatti per l'equivalenza tra semantica di
computazione e semantica di valutazione:
\begin{align*}
  &E\ \rightarrow\ E_1\ \twoheadrightarrow\ n\\
  &E\ \rightarrow\ E_1\ \xrightarrow{*}\ n\\
  &E\ \xrightarrow{*}\ n\\
  &E\ \twoheadrightarrow\ n
\end{align*}
Oppure in modo analogo passando da $E_2$.

La dimostrazione procede per induzione sulla lunghezza dell'espressione $E$, o in modo
equivalente sul numero di operatori in $E$.

\paragraph{Caso base:}Per il caso base si considera un'espressione $E$ con un operatore (non possono esserci zero
operatori altrimenti non si potrebbe applicare l'ipotesi), l'unica regola
applicabile è la $(op)$ della semantica di computazione, e quindi se
$E\ \rightarrow\ E_1$ e $E\ \rightarrow\ E_2$ allora
$E_1=E_2=n$ e vale la tesi.

\paragraph{Passo induttivo:}Per una generica espressione $E$ tale che
$E\ \rightarrow\ E_1$ e $E\ \rightarrow\ E_2$, si pu\`o osservare che se
\`e stata usata $(op)$ nel passo $E\ \rightarrow\ E_1$ significa che
$E = m_1\ op\ m_2$ e quindi ha un solo operatore e siamo nel caso base.

Se \`e stata usata $(redl)$ nel passo $E\ \rightarrow\ E_1$ significa che
$E$ non \`e in una forma in cui \`e possibile applicare $(op)$ quindi
nel passo $E\ \rightarrow\ E_2$ \`e possibile solo applicare $(redl)$
o $(redr)$. Nel Primo caso significa che $E_1=E_2$ e non \`e
rilevante per la dimostrazione, quindi assumiamo che sia stata usata
$(redr)$. Chiamando $E\equiv E_a\ op\ E_b$, $E_1\equiv E_a'\ op\ E_b$,
$E_2\equiv E_a\ op\ E_b'$ si hanno:
\begin{align*}
  &\inferrule* [right=$(redl)$] {
    E_a\ \rightarrow\ E_a'
  }{
    E_a\ op\ E_b\ \rightarrow\ E_a'\ op\ E_b
  }\\
  \\
  &\inferrule* [right=$(redr)$] {
    E_b\ \rightarrow\ E_b'
  }{
    E_a\ op\ E_b\ \rightarrow\ E_a\ op\ E_b'
  }
\end{align*}
Si noti che \`e stato possibile escludere che $E_1=k_1$ o $E_2=k_2$ in
quanto in questi casi si esclude che sia possibile applicare $(redl)$
e $(redr)$ contemporaneamente e si riduce ad un caso banale.

$E_a$ e $E_b$ sono pi\`u corte di $E$ quindi si pu\`o applicare l'ipotesi
induttiva, in modo che per qualunque coppia di cammini intrapresi
$E_a\ \rightarrow\ E_{a1}$, $E_a\ \rightarrow\ E_{a2}$,
$E_b\ \rightarrow\ E_{b1}$, $E_b\ \rightarrow\ E_{b2}$, si ha che
$E_{a1}\ \twoheadrightarrow\ m_a$, $E_{a2}\ \twoheadrightarrow\ m_a$,
$E_{b1}\ \twoheadrightarrow\ m_b$, $E_{b2}\ \twoheadrightarrow\
m_b$ e, per quanto detto nella premessa,
anche $E_a\ \twoheadrightarrow\ m_a$ e $E_b\ \twoheadrightarrow\
m_b$. Di conseguenza valgono:
\begin{align*}
  &E_a\ \twoheadrightarrow\ m_a\\
  &E_b\ \twoheadrightarrow\ m_b\\
  &E_a'\ \twoheadrightarrow\ m_a\\
  &E_b'\ \twoheadrightarrow\ m_b\\
\end{align*}
e si pu\`o applicare:
\begin{align*}
  &\inferrule* [right={$(m_a\ op\ m_b\ =\ n)$}] {
    E_a'\ \twoheadrightarrow\ m_a\qquad E_b\ \twoheadrightarrow\ m_b
  }{
    E_a'\ op\ E_b\ \twoheadrightarrow\ n
  }\\
  \\
  &\inferrule* [right={$(m_a\ op\ m_b\ =\ n)$}] {
    E_a\ \twoheadrightarrow\ m_a\qquad E_b'\ \twoheadrightarrow\ m_b
  }{
    E_a\ op\ E_b'\ \twoheadrightarrow\ n
  }
\end{align*}
Dimostrando che $E_1\ \twoheadrightarrow\ n$ e $E_2\
\twoheadrightarrow\ n$, e quindi la tesi.

\sectionline
\section*{\hyperref[toc]{Esercizio 4.11}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 4.11}
\subsection*{Testo:}
Relativamente all’Esempio~4.10, si dimostri che se $s$ \`e una traccia
di $F$ (ossia $F\Rightarrow 1$) allora $s$
è una traccia anche di $E$.

\subsection*{Soluzione:}
\`E necessario dimostrare che se $F\xRightarrow{s} 1$ allora
$E\xRightarrow{s}1$.
La dimostrazione procede per induzione sulla lunghezza della traccia
$s$.
\paragraph{Caso base $|s|=0$} se la traccia \`e di lunghezza zero,
allora essa \`e necessariamente $s=\varepsilon$, e quindi la tesi \`e
dimostrata perch\'e vale $E\ \xRightarrow{s}\ 1$ per l'assioma $(Star_1)$.

\paragraph{Passo induttivo $|s|>1$} si ha che la traccia pu\`o essere
$s=as'$ oppure $s=bs'$, e senza perdere di generalit\`a si assume il
primo caso. Inoltre vale l'ipotesi induttiva che se
$F\xRightarrow{s'}1$ allora $E\xRightarrow{s'}1$.

Vale che 
$$
F\ \xrightarrow{a}\ 1;a^*;F\ \xrightarrow{\varepsilon}\ a;F\
\xrightarrow{\varepsilon}\ F\ \xrightarrow{\varepsilon}\ 1;F\
\xrightarrow{\varepsilon}\ F\ \xrightarrow{\varepsilon}\ 1
$$
o in altri termini valgono:
\begin{eqnarray*}
  F\ \xRightarrow{a}&1;a^*;F&\xRightarrow{\varepsilon}\ F\\
  F\ \xRightarrow{a}&a;F&\xRightarrow{\varepsilon}\ F\\
  F\ \xRightarrow{a}&F&\xRightarrow{\varepsilon}\ F\\
  F\ \xRightarrow{a}&1;F&\xRightarrow{\varepsilon}\ F\\
  F\ \xRightarrow{a}&1
\end{eqnarray*}
Che sono anche le uniche transizioni che $F$ pu\`o eseguire tramite
$a$, giustificate dalle:
\begin{align*}
  &\inferrule* [right=$(Star_2)$] {
    \inferrule* [right=$(Sum_1)$] {
      \inferrule* [right=$(Star_2)$] {
        \inferrule* [right=$(Atom)$] { }{
          a\ \xrightarrow{a}\ 1
        }
      }{
        a^*\ \xrightarrow{a}\ 1;a^*
      }
    }{
      a^*+b^*\ \xrightarrow{a}\ 1;a^*
    }
  }{
    (a^*+b^*)^*\ \xrightarrow{a}\ 1;a^*;(a^*+b^*)^*
  }\\
  \\
  &\inferrule* [right=$(Seq_2)$] {
    \inferrule* [right=$(Tic)$] { }{
      1\ \xrightarrow{\varepsilon}\ 1
    }
  }{
    1;a^*;(a^*+b^*)^*\ \xrightarrow{\varepsilon}\ a^*;(a^*+b^*)^*
  }\\
  \\
  &\inferrule* [right=$(Seq_2)$] {
    \inferrule* [right=$(Star_1)$] { }{
      a*\ \xrightarrow{\varepsilon}\ 1
    }
  }{
    a^*;(a^*+b^*)^*\ \xrightarrow{\varepsilon}\ (a^*+b^*)^*
  }\\
  \\
  &\inferrule* [right=$(Star_2)$] {
    \inferrule* [right=$(Sum_1)$ {\tiny(o similmente $(Sum_2)$)}] {
      \inferrule* [right=$(Star_1)$] { }{
        a^*\ \xrightarrow{\varepsilon}\ 1
      }
    }{
      a^*+b^*\ \xrightarrow{\varepsilon}\ 1
    }
  }{
    (a^*+b^*)^*\ \xrightarrow{\varepsilon}\ 1;(a^*+b^*)^*
  }\\
  \\
  &\inferrule* [right=$(Seq_2)$] {
    \inferrule* [right=$(Tic)$] { }{
      1\ \xrightarrow{\varepsilon}\ 1
    }
  }{
    1;(a^*+b^*)^*\ \xrightarrow{\varepsilon}\ (a^*+b^*)^*
  }\\
  \\
  &\inferrule* [right=$(Star_1)$] { }{
    (a^*+b^*)^*\ \xrightarrow{\varepsilon}\ 1
  }
\end{align*}

Per ipotesi: $F \xRightarrow{as'}\ 1$, e per quanto detto prima,
dopo aver fatto una $\xRightarrow{a}$ si ha che vale $X\
\xRightarrow{s'}\ 1$ con $X$ che pu\`o essere uno dei:
\begin{align*}
  &1;a^*;F\\
  &a;F\\
  &F\\
  &1;F\\
  &1  
\end{align*}
Nell'ultimo caso si ha che necessariamente $s'=\varepsilon$ e
$s=a$, la tesi vale perch\'e esiste la computazione $E\
\xrightarrow{a}\ 1;(a+b)^*\ \xrightarrow{\varepsilon}\ E\
\xrightarrow{\varepsilon}\ 1$ e quindi $E\ \xRightarrow{a}\ 1$. Tale
computazione \`e giustificata dalle regole:
\begin{align*}
  &\inferrule* [right=$(Star_2)$] {
    \inferrule* [right=$(Sum_1)$] {
      \inferrule* [right=$(Atom)$] { }{
        a\ \xrightarrow{a}\ 1
      }
    }{
      a+b\ \xrightarrow{a}\ 1
    }
  }{
    (a+b)^*\ \xrightarrow{a}\ 1;(a+b)^*
  }\\
  \\
  &\inferrule* [right=$(Seq_2)$] {
    \inferrule* [right=$(Tic)$] { }{
      1\ \xrightarrow{\varepsilon}\ 1
    }
  }{
    1;(a+b)^*\ \xrightarrow{\varepsilon}\ (a+b)^*
  }\\
  \\
  &\inferrule* [right=$(Star_1)$] { }{
    (a+b)^*\ \xrightarrow{\varepsilon}\ 1
  }
\end{align*}

Per gli
altri casi si ha che $X\ \xRightarrow{\varepsilon}\ F$ \`e l'unica
computazione possibile, quindi $F\ \xRightarrow{a}\ X\ \xRightarrow{\varepsilon}\ F\
\xRightarrow{s'}\ 1$ e usando l'ipotesi induttiva vale che $E\
\xRightarrow{s'}\ 1$. La tesi si ottiene giustificando che esiste $E\
\xRightarrow{a}\ E$ e quindi $E\ \xRightarrow{as'=s}\ 1$. Per fare
ci\`o si noti che esistono i passi $E\ \xrightarrow{a}\ 1;E\
\xrightarrow{\varepsilon}\ E$ gi\`a giustificati con regole viste prima.

\sectionline
\section*{\hyperref[toc]{Esercizio 5.5}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 5.5}
\subsection*{Testo:}
Dati:
\begin{eqnarray*}
  \mathbf{S}&\equiv&\lambda xyz.xz(yz)\\
  \mathbf{K}&\equiv&\lambda xy.x\\
  \mathbf{I}&\equiv&\lambda x.x
\end{eqnarray*}
mostrare che $\mathbf{SK}=\mathbf{KI}$.
\subsection*{Soluzione:}
Valgono i passaggi:
\begin{eqnarray*}
  \mathbf{SK}&=&(\lambda xyz.xz(yz))(\lambda xy.x)\\
  &\betaReduction&\lambda yz.(\lambda xy.x)z(yz)\\
  &\betaReduction&\lambda yz.(\lambda y.z)(yz)\\
  &\betaReduction&\lambda yz.z\\
  &\equiv&\lambda xy.y
\end{eqnarray*}
e anche:
\begin{eqnarray*}
  \mathbf{KI}&=&(\lambda xy.x)(\lambda x.x)\\
  &\betaReduction&\lambda y.(\lambda x.x)\\
  &\equiv&\lambda yx.x\\
  &\equiv&\lambda xy.y\\
\end{eqnarray*}
quindi la tesi \`e dimostrata perch\`e i due termini riducono alla
stessa forma. 

\sectionline
\section*{\hyperref[toc]{Esercizio 6.10}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 6.10}
\subsection*{Testo:}
Sia $D$ un cpo. Una funzione $r : D \rightarrow D$ si dice idempotente
se $r(r(x)) = r(x)$, per ogni $x \in D$.
Dimostrare che l’insieme di tutte le funzioni continue idempotenti da
$D$ in $D$ è un cpo.
\subsection*{Soluzione:}
Poich\'e $D$ \`e un cpo, lo spazio delle funzioni continue da $D$ a
$D$ denotato da $[D\rightarrow D] = (D\rightarrow D, \sqsubseteq)$,
cos\`i come in definizione 6.33, \`e un cpo. L'insieme delle funzioni
continue e idempotenti $G$ \`e un sottoinsieme dell'insieme delle funzioni
continue $D\rightarrow D$, quindi considerando $\sqsubseteq_G$ la
restrizione di $\sqsubseteq$ a $G$, si ha che $\mathbb{G} = (G,\sqsubseteq_G)$ \`e
un poset. Per dimostrare che $\mathbb{G}$ \`e anche un cpo \`e
necessario mostrare che con la restrizione da $[D\rightarrow D]$ a
$\mathbb{G}$ vengono mantenuti il minimo (punto 1) e i $\sup$ di ogni
catena in $\mathbb{G}$ (punto 2).
\begin{enumerate}
\item Il minimo di $[D\rightarrow D]$ \`e $\Omega\equiv\lambda
  x.\perp_D$ con $\perp_D$ il minimo di $D$. Tale funzione \`e anche
  idempotente perch\'e $\Omega(x)=\Omega(\Omega(x))=\perp_D$ per
  qualunque $x$, quindi appartiene anche a $G$.
\item Data una generica catena di funzioni continue e idempotenti
  $\{f_i|i\in I\}$, \`e necessario dimostrare che il $\sup$ di tale
  catena, che sappiamo dalla dimostrazione del teorema 6.34 essere:
  $$g\equiv\lambda x.\sup\{ f_i x|i\in I\}$$
  sia $\in G$ e quindi idempotente, e quindi che $g(g x)=g(x)$ per
  ogni $x$.

  La dimostrazione procede nel seguente modo:
  \begin{eqnarray*}
    g(g x)&=&(\lambda x'.\sup\{f_i x'|i\in I\})((\lambda x''.\sup\{f_i x''|i\in I\})x)\\
    &=&(\lambda x'.\sup\{f_i x'|i\in I\})\sup\{f_i x|i\in I\}\\
    &=&\sup\{f_i (\sup\{f_j x|j\in I\})|i\in I\}
  \end{eqnarray*}
  e per la continuit\`a delle $f_i$
  \begin{eqnarray*}
    &=&\sup\{\sup\{f_i (f_j x)|j\in I\}|i\in I\}
  \end{eqnarray*}
  a questo punto disponendo in forma matriciale ordinata gli $f_i$ e
  gli $f_j$ \`e possibile applicare la proposizione 6.27(2) e si
  ottiene
  \begin{eqnarray*}
    &=&\sup\{f_i(f_i x)|i\in I\}
  \end{eqnarray*}
  e poich\'e tutte le $f_i$ sono idempotenti
  \begin{eqnarray*}
    &=&\sup\{f_i x|i\in I\}\\
    &=&g x
  \end{eqnarray*}
  \qed
\end{enumerate}

\sectionline
\section*{\hyperref[toc]{Esercizio 7.6}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 7.6}
\subsection*{Testo:}
Fornire semantica operazionale e denotazionale del programma
$$
\mathbf{letrec} f(x) \Leftarrow f(x) \mathbf{in} f(5)  
$$

\subsection*{Soluzione:}
Cominciando con la semantica operazionale con chiamata per nome si ha:
$$
f(5) \xrightarrow{(FUN)}_D f(5) \xrightarrow{(FUN)}_D \dots
$$
e in modo simile per quella con chiamata per valore usando
$(FUN')$. Quindi divergono.

Per la semantica denotazionale, usando un approccio bottom up, si ha:
\begin{eqnarray*}
  \mathcal{T}[[5]]&=&\lambda f.\lambda x. 5\\
  \mathcal{T}[[x]]&=&\lambda f.\lambda x. x\\
  \mathcal{T}[[f(5)]]&=&\lambda f.\lambda x. f(\mathcal{T}[[5]]fx)\\
  &=&\lambda f.\lambda x.f(5)\\
  \mathcal{T}[[f(x)]]&=&\lambda f.\lambda x. f(\mathcal{T}[[x]]fx)\\
  &=&\lambda f.\lambda x.f((\lambda f.\lambda x'.x')fx)\\
  &=&\lambda f.\lambda x.f(x)\\
  \mathcal{D}[[f(x)\Leftarrow f(x)]]&=&fix(\lambda
  f.\mathcal{T}[[f(x)]]f)\\
  &=&fix(\lambda f.(\lambda f'.\lambda x.f'(x))f)\\
  &=&fix(\lambda f.\lambda x. f(x))\\
  &=&\sup\{(\lambda f.\lambda x. f(x))^i\lambda x.\perp|i\in\mathbb{N}\}\\
  &=&\lambda x.\perp\\
  &=&\Omega\\
  \mathcal{P}[[\mathbf{letrec} f(x) \Leftarrow f(x) \mathbf{in} f(5)
  ]]&=&\mathcal{T}[[f(5)]]\mathcal{D}[[f(x)\Leftarrow f(x)]]0\\
  &=&(\lambda f.\lambda x.f(5))\Omega 0\\
  &=&\Omega 5\\
  &=&\perp
\end{eqnarray*}

Dalla valutazione della semantica operazionale si nota che il
programma diverge, e infatti
la valutazione della semantica denotazionale lo conferma restituendo, come
prevedibile, un risultato non definito.

\sectionline
\section*{\hyperref[toc]{Esercizio 8.11}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 8.11}
\subsection*{Testo:} Si aggiunga al linguaggio TINY un comando $\mathbf{stop}$
con la semantica informale di far terminare il 
programma. Se ne dia la semantica e si dimostri che $c 1 ; \mathbf{stop}$ e $c 1 ;
\mathbf{stop}; c 2$ sono semanticamente
equivalenti.

\subsection*{Soluzione:}
\`E possibile estendere la semantica operazionale in modo da gestire
lo $\mathbf{stop}$ modificando leggermente $(\text{Seq}_2)$ in:
$$
\frac{<c_1,\sigma>\ \longrightarrow\ <c_1',\sigma'>}{<c_1;c_2,\sigma>\
  \longrightarrow\ <c_1';c_2,\sigma'>}(c_1'\neq\mathbf{stop})\qquad (\text{Seq}_2')
$$
e aggiungendo le due regole
\begin{align*}
<\mathbf{stop},\sigma>&\longrightarrow{} <\mathbf{noaction},\sigma>&(\text{Stop}_1)\\
<\mathbf{stop};c,\sigma>&\longrightarrow{} <\mathbf{stop},\sigma>&(\text{Stop}_2)
\end{align*}

Per quanto riguarda la semantica denotazionale \`e pi\`u difficile
ottenere lo stesso risultato. \`E necessario cambiare anche il dominio
delle funzioni di interpretazione semantica dei comandi in:
$$
\mathcal{C}: Com\longrightarrow{}\mathbb{STATO}\longrightarrow{}(\mathbb{STATO}+(\mathbb{STATO}\times\{stop\})+\{error\})
$$
per aggiungere la possibilit\`a che la computazione ritorni una coppia
$<\sigma,stop>$ che va letta come lo stato $\sigma$ con
l'aggiunta dell'informazione che la computazione \`e terminata a causa
di un comando $\mathbf{stop}$. Va quindi modificata la denotazione
corrispondente alla sequenzializzazione di comandi in:
\begin{align*}
  \mathcal{C}\llbracket c_1;c_2\rrbracket&= \lambda\sigma.cases (\mathcal{C}\llbracket c_1\rrbracket\sigma)
  of\\
&\qquad\qquad\sigma':\mathcal{C}\llbracket c_2\rrbracket\sigma';\\
&\qquad\qquad<\sigma',stop>:<\sigma',stop>;\\
&\qquad\qquad error : error\\
&\qquad endcases
\end{align*}
e aggiunta la denotazione per lo $\mathbf{stop}$:
$$
\mathcal{C}\llbracket\mathbf{stop}\rrbracket=\lambda\sigma.<\sigma,\mathbf{stop}>
$$
Con queste aggiunte andrebbero anche riviste e  modificate la dimostrazione di
equivalenza tra le due semantiche e la formalizzazione in punto fisso della
denotazione del $\mathbf{while}$ che fa uso della
sequenzializzazione. Queste ultime modifiche vengono tralasciate
perch\'e non inerenti all'esercizio.

Per dimostrare che $c_1;\mathbf{stop}$ e $c_1;\mathbf{stop};c_2$ sono
semanticamente equivalenti, si pu\`o usare la semantica operazionale
per mostrare che le computazioni dei due programmi portano a
configurazioni finali con stati identici, dato
un qualsiasi
stato iniziale $\sigma$.
Per $c_1;\mathbf{stop}$ vale che:
\begin{gather*}
  <c_1;stop,\sigma>\\
  \downarrow_{(\text{Seq}_2')}\\
  <stop,\sigma'>\\
  \downarrow_{(\text{Stop}_1)}\\
  <noaction,\sigma'>\\
\end{gather*}
dove \`e stata usata l'istanza di $(\text{Seq}_2')$:
$$
\frac{<c_1,\sigma> \longrightarrow{}
  <c_1',\sigma'>}{<c_1;\mathbf{stop},\sigma> \longrightarrow{}
  <\mathbf{stop},\sigma'>}
$$

Per $c_1;\mathbf{stop};c_2$ vale che:
\begin{gather*}
  <c_1;stop;c_2,\sigma>\\
  \downarrow_{(\text{Seq}_2')}\\
  <stop;c_2,\sigma'>\\
  \downarrow_{(\text{Stop}_2)}\\
  <stop,\sigma'>\\
  \downarrow_{(\text{Stop}_1)}\\
  <noaction,\sigma'>\\
\end{gather*}
dove \`e stata usata l'istanza di $(\text{Seq}_2')$:
$$
\frac{<c_1,\sigma> \longrightarrow{}
  <c_1',\sigma'>}{<c_1;\mathbf{stop};c_2,\sigma> \longrightarrow{}
  <\mathbf{stop};c_2,\sigma'>}
$$
con $c_1'$ e $\sigma'$ gli stessi di prima in quanto la premessa è la
stessa. Quindi poich\'e entrambe le computazioni hanno lo stesso stato
finale $<\mathbf{noaction},\sigma'>$, la tesi
\`e vera.

\`E possibile anche dimostrare l'equivalenza usando la semantica
denotazionale, osservando che sia nella denotazione di $\mathcal{C}\llbracket
c_1;\mathbf{stop}\rrbracket$ che in quella di $\mathcal{C}\llbracket
c_1;\mathbf{stop};c_2\rrbracket$ viene prima valutato $\mathcal{C}\llbracket
c_1\rrbracket$ e poi applicato $\sigma'$ a $\mathcal{C}\llbracket
\mathbf{stop}\rrbracket$ in un caso e $\mathcal{C}\llbracket
\mathbf{stop};c_2\rrbracket$ nell'altro. In seguito l'unica differenza
\`e che nel primo caso vale subito che $\mathcal{C}\llbracket
\mathbf{stop}\rrbracket\sigma'$ \`e $<\sigma',stop>$, nel secondo caso
c'è un ulteriore passaggio in cui viene usato il secondo \emph{case}
della denotazione della sequenzializzazione e che per\`o non cambia il
risultato.

\sectionline
\section*{\hyperref[toc]{Esercizio 9.7}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 9.7}
\subsection*{Testo:} Estendere il linguaggio SMALL introducendo i
comandi $\mathbf{restart}$ ed $\mathbf{exit}$, il cui significato è di 
saltare rispettivamente all’inizio ed alla fine del blocco più
interno.

\subsection*{Soluzione:} Per gestire i due comandi richiesti \`e
necessario modificare il dominio:
\begin{equation*}
  \begin{multlined}  
    \mathcal{C}:Com \longrightarrow{} \mathbb{AMB}
    \longrightarrow{} \mathbb{MEM} \longrightarrow{}\\
    \qquad\qquad\qquad\qquad((\mathbb{MEM}\times\{restart, stop, normal\})+\{error\})
  \end{multlined}  
\end{equation*}

che aggiunge la possibilit\`a per i comandi di indicare il tipo di
ritorno in abbinamento al valore di ritorno della
memoria. Informalmente $normal$ indica che la valutazione del comando
che li ha ritornati
non ha portato a nessun comando di $\mathbf{stop}$ o
$\mathbf{restart}$; $stop$ e $restart$ indicano che la valutazione del
comando ha portato rispettivamente ad uno $\mathbf{stop}$ e ad un
$\mathbf{restart}$.

Per gestire il cambio di flusso del programma vengono modificate le regole di interpretazione semantica di programmi, di blocchi, e
della sequenzializzazione nel seguente modo:
\begin{align*}
  \mathcal{P}\llbracket\mathbf{program}\ c\rrbracket in\ =\ &fix(\lambda\Theta.cases
  (\mathcal{C}\llbracket c\rrbracket\rho_0(\lambda
  x.unused)[in/lin][nil/lout]) of\\
  &\qquad<\sigma,normal> : \sigma(lout);\\
  &\qquad<\sigma,stop> : \sigma(lout);\\
  &\qquad<\sigma,restart> : \Theta\\
  &endcases)
\end{align*}
\begin{align*}
  \mathcal{C}\llbracket\mathbf{begin}\ d;\ c\
  \mathbf{end}\rrbracket\rho\ =\ &fix(\lambda\Theta.\mathcal{D}\llbracket d\rrbracket\rho\
  \star\ \lambda\rho'.\mathcal{C}\llbracket c\rrbracket\rho[\rho']\
  \star\ \lambda\sigma s.\ cases\ s\ in:\\
  & \qquad normal:<\sigma,normal>;\\
  & \qquad stop:<\sigma,normal>;\\
  & \qquad restart:\Theta\\
  &endcases)
\end{align*}
\begin{align*}
  \mathcal{C}\llbracket c_1;c_2\rrbracket\rho\ =\ &\mathcal{C}\llbracket
  c_1\rrbracket\rho\ \star\ \lambda\sigma s.\ cases\ s\ in:\\
  & \qquad normal:\mathcal{C}\llbracket c_2\rrbracket\rho;\\
  & \qquad stop:<\sigma,\ stop>;\\
  & \qquad restart:<\sigma,\ restart>;\\
  & endcases
\end{align*}

Oltre a queste regole \`e necessario modificare leggermente le altre regole
di interpretazione dei comandi per dare in output la coppia $<\sigma,\
normal>$ invece della sola memoria:
\begin{align*}
  \mathcal{C}\llbracket e:=e'\rrbracket\rho\ =\ &\mathcal{E}\llbracket
  e\rrbracket\rho\ \star\ checkLOC\ \star\ \lambda
  l.\mathcal{R}\llbracket e'\rrbracket\rho\ \star\\
  &\qquad\qquad\qquad\qquad\lambda
  v\sigma.<\sigma[v/l],\ normal>
\end{align*}
\begin{align*}
  \mathcal{C}\llbracket\mathbf{while}\ e\ \mathbf{do}\ c\rrbracket\rho\
  =\ &fix(\lambda\Theta.\mathcal{R}\llbracket e\rrbracket\rho\ \star\
  checkBOOL\\
  &\qquad\qquad\star\ \lambda b.b\rightarrow\mathcal{C}\llbracket
  c\rrbracket\rho\ \star\ \Theta,\ \lambda\sigma.<\sigma,\ normal>)
\end{align*}
\begin{align*}
  \mathcal{C}\llbracket\mathbf{output}\ e\rrbracket\rho\ =\ 
  &\mathcal{R}\llbracket e\rrbracket\rho\ \star\ \lambda
  b\sigma.<\sigma[b::\sigma(lout)/lout],\ normal>
\end{align*}
Non \`e invece necessario modificare le regole per l'$\mathbf{if}$ e
per l'applicazione di procedure, in quanto la coppia viene generata a
livello superiore.

Infine \`e necessario specificare le regole di interpretazione
semantica per i due nuovi comandi $\mathbf{stop}$ e
$\mathbf{restart}$:
\begin{align*}
  \mathcal{C}\llbracket\mathbf{stop}\rrbracket\rho\ =\
  \lambda\sigma.<\sigma,\ stop>
\end{align*}
\begin{align*}
  \mathcal{C}\llbracket\mathbf{restart}\rrbracket\rho\ =\
  \lambda\sigma.<\sigma,\ restart>
\end{align*}

\sectionline
\section*{\hyperref[toc]{Esercizio 11.10}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 11.10}
\subsection*{Testo:}
Si dimostri la Proposizione 11.34 che fornisce una definizione
alternativa di bisimulazione.

{\tiny
(Sia $<Q, A, \rightarrow >$ un LTS. Una relazione $R \subseteq Q \times Q$ è una bisimulazione se e solo se $R$ e $R^{-1}$
sono simulazioni.)
}
\subsection*{Soluzione:}
Si dimostrano i due lati della doppia implicazione. Nel testo di
questo esercizio ``$\implies$'' \`e da intendersi come ``\emph{implica}'', e
non come sinonimo di ``$\xRightarrow{\varepsilon}$''.
\paragraph{($\implies$)} Si dimostra che se $R$ \`e una
bisimulazione, allora $R$ e $R^{-1}$ sono simulazioni.

Per il punto~1 della
definizione~11.8 si ha che 
\begin{align*}
&\forall <p,q>\in R,\text{ vale:}\\
&\quad\forall a\in A,\ \forall p'\in Q:\\
&\quad\quad(p\xrightarrow{a} p')\implies\exists q'\in Q:(q\xrightarrow{a} q'\
\land\ <p',q'>\in R),
\end{align*}
ma se vale questo vale anche che $R$ \`e
una simulazione per la definizione~11.31.

Per il punto~2 della definizione~11.8 si ha che
\begin{align*}
&\forall <p,q>\in R,\text{ vale:}\\
&\quad\forall a\in A,\ \forall q'\in Q:\\
&\quad\quad(q\xrightarrow{a} q')\implies\exists p'\in Q:(p\xrightarrow{a} p'\
\land\ <p',q'>\in R),
\end{align*}
per la definizione di relazione inversa si ha
$<q,p>\in R^{-1}\iff<p,q>\in R$, quindi
\begin{align*}
&\forall <q,p>\in R^{-1},\text{ vale:}\\
&\quad\forall a\in A,\ \forall q'\in Q:\\
&\quad\quad(q\xrightarrow{a} q')\implies\exists p'\in Q:(p\xrightarrow{a} p'\
\land\ <q',p'>\in R^{-1}).
\end{align*}
Ridenominando $p$ in $q$, $p'$ in $q'$, $q$ in $p$ e $q'$ in $p'$,
tutte quantificate, si ottiene che $R^{-1}$ \`e una simulazione 
dalla definizione~11.31.

\paragraph{($\impliedby$)} Si dimostra che se $R$ e $R^{-1}$ sono
simulazioni, allora $R$ \`e una bisimulazione.

Applicando la definizione~11.31 ad $R$ ed $R^{-1}$, ridenominando
nella seconda $p$
in $q$, $p'$ in $q'$, $q$ in $p$ e $q'$ in $p'$ si ha
\begin{align*}
&\forall <p,q>\in R,\text{ vale:}\\
&\quad\forall a\in A,\ \forall p'\in Q:\\
&\quad\quad(p\xrightarrow{a} p')\implies\exists q'\in Q:(q\xrightarrow{a} q'\
\land\ <p',q'>\in R),
\\
&\forall <q,p>\in R^{-1},\text{ vale:}\\
&\quad\forall a\in A,\ \forall q'\in Q:\\
&\quad\quad(q\xrightarrow{a} q')\implies\exists p'\in Q:(p\xrightarrow{a} p'\
\land\ <q',p'>\in R^{-1}),
\end{align*}
per la definizione di relazione inversa si ha
$<q,p>\in R^{-1}\iff<p,q>\in R$, quindi
\begin{align*}
&\forall <p,q>\in R,\text{ vale:}\\
&\quad\forall a\in A,\ \forall p'\in Q:\\
&\quad\quad(p\xrightarrow{a} p')\implies\exists q'\in Q:(q\xrightarrow{a} q'\
\land\ <p',q'>\in R),
\\
&\forall <p,q>\in R,\text{ vale:}\\
&\quad\forall a\in A,\ \forall q'\in Q:\\
&\quad\quad(q\xrightarrow{a} q')\implies\exists p'\in Q:(p\xrightarrow{a} p'\
\land\ <p',q'>\in R),
\end{align*}
o in modo alternativo
\begin{align*}
&\forall <p,q>\in R,\text{ valgono:}\\
&\quad\forall a\in A,\ \forall p'\in Q:\\
&\quad\quad(p\xrightarrow{a} p')\implies\exists q'\in Q:(q\xrightarrow{a} q'\
\land\ <p',q'>\in R),
\\
&\quad\forall a\in A,\ \forall q'\in Q:\\
&\quad\quad(q\xrightarrow{a} q')\implies\exists p'\in Q:(p\xrightarrow{a} p'\
\land\ <p',q'>\in R),
\end{align*}
e, per la definizione~11.8, $R$ \`e una bisimulazione.

\sectionline
\section*{\hyperref[toc]{Esercizio 12.1}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 12.1}
\subsection*{Testo:}
Dimostrare la proposizione seguente che introduce alcune leggi per gli
operatori statici derivabili 
a partire da quelle nelle Tabelle~12.6, 12.7 e~12.8.
\paragraph{Proposizione~12.64 (Leggi derivabili).} Le seguenti leggi
\begin{enumerate}
\item $p|q\ =\ q|p$
\item $p|(q|r)\ =\ (p|q)|r$
\item $p|nil\ =\ p$
\item $p \backslash L \ =\  p\quad\text{ se }\mathcal{L}(p) \cap (L \cup \overline{L}) = \emptyset$
\item $p \backslash K \backslash L \ =\  p \backslash (K \cup L)$
\item $p[f] \backslash L \ =\  p \backslash f^{-1} (L)[f]$
\item $(p|q) \backslash L \ =\  p \backslash L|q \backslash L\quad\text{ se }\mathcal{L}(p) \cap \overline{\mathcal{L}(q)} \cap (L \cup L) = \emptyset$
\item $p[Id] \ =\  p$
\item $p[f] \ =\  p[f']\quad\text{ se }f \upharpoonright \mathcal{L}(p) = f'\upharpoonright \mathcal{L}(p)$
\item $p[f][f'] \ =\  p[f \circ f']$
\item $(p|q)[f] \ =\  p[f]|q[f]\quad\text{ se }f \upharpoonright (L \cup \overline{L})\text{ è biunivoca, dove }L = \mathcal{L}(p) \cup \mathcal{L}(q)$
\end{enumerate}
sono corrette rispetto a $\sim$.
\subsection*{Soluzione:}
Per ognuna delle regole $t_1\ =\ t_2$ \`e necessario verificare che esiste una
bisimulazione forte $R$ tale che $<t_1,t_2>\in R$. La struttura della
dimostrazione \`e simile per tutti i punti, si definisce
$$
R\triangleq\{<t_1,t_2>:t_1,t_2\in\mathcal{P}_{CCS}\}\cup Id
$$
e si procede quindi a dimostrare che $R$ \`e chiusa rispetto alle
transizioni. Alternativamente \`e possibile dimostrare che
$\forall\mu\in\mathcal{A}_{CCS}:\ t_1\xrightarrow{\mu}t\iff
t_2\xrightarrow{\mu}t$. 
\begin{enumerate}
\item \enbox{$p|q=q|p$}: Se $p|q\xrightarrow{\mu}t$ significa che è stata usata una tra
  $(PAR1)$, $(PAR2)$ e $(PAR3)$, quindi si ha che
  \begin{itemize}
  \item $p\xrightarrow{\mu}p'$ e quindi $t=p'|q$ oppure
  \item $q\xrightarrow{\mu}q'$ e quindi $t=p|q'$ oppure
  \item se $\mu = \tau$: $p\xrightarrow{\alpha}p''$ e
    $q\xrightarrow{\overline{\alpha}}q''$ per qualche $\alpha$  e quindi $t=p''|q''$.
  \end{itemize}
  Quindi per le stesse regole vale che $q|p\xrightarrow{\mu}t'$ e
  \begin{itemize}
  \item $p\xrightarrow{\mu}p'$ e quindi $t'=q|p'$ oppure
  \item $q\xrightarrow{\mu}q'$ e quindi $t'=q'|p$ oppure
  \item se $\mu = \tau$: $p\xrightarrow{\alpha}p''$ e
    $q\xrightarrow{\overline{\alpha}}q''$ per qualche $\alpha$  e quindi $t'=q''|p''$.
  \end{itemize}
 La tesi viene dal fatto che qualunque percorso viene scelto
 $t$ e $t'$ rimangono in forma $p|q$ e $q|p$ e quindi $<t,\ t'>\in R$.
\item \enbox{$p|(q|r)=(p|q)|r$}: La dimostrazione avviene mostrando che
  $R$ \`e chiusa rispetto alle transizioni.

  In maniera schematica è
  possibile vedere che se per un generico $\mu$ si ha
  $p|(q|r)\xrightarrow{\mu}t$ allora a seconda di che regole vengono
  usate, $t$ pu\`o essere in una delle forme riassunte nello schema
  seguente (dove $\implies$ \`e l'implicazione):
  \begin{itemize}
  \item $(PAR1):\quad p\xrightarrow{\mu}p'\quad\implies\quad t=p'(q|r)\ \encircle{$P_1$}$
  \item $(PAR2):\quad (q|r)\xrightarrow{\mu}t'\quad\implies$ uno tra:
    \begin{itemize}
    \item $(PAR1):\quad q\xrightarrow{\mu}q'\quad\implies\quad t'=q'|r\quad\implies\quad t=p|(q'|r)\ \encircle{$Q_1$}$
    \item $(PAR2):\quad r\xrightarrow{\mu}r'\quad\implies\quad t'=q|r'\quad\implies\quad t=p|(q|r')\ \encircle{$R_1$}$
    \item $(SINC):\quad \mu=\tau,\ q\xrightarrow{\alpha}q_1'',\ r\xrightarrow{\overline{\alpha}}r_1''\quad\implies$\\
      \hbox{}\hfill$t'=q_1''|r_1''\quad\implies\quad t=p|(q_1''|r_1'')\ \encircle{$QR_1$}$
    \end{itemize}
  \item $(SINC):\quad \mu=\tau,\ p\xrightarrow{\beta}p_1'',\ (q|r)\xrightarrow{\overline{\beta}}t_1''\quad\implies$ uno tra:
    \begin{itemize}
    \item $(PAR1):\quad q\xrightarrow{\overline{\beta}}q_1'''\implies t_1''=q_1'''|r\quad\implies\quad t=p_1''|(q_1'''|r)\ \encircle{$PQ_1$}$
    \item $(PAR2):\quad r\xrightarrow{\overline{\beta}}r_1'''\implies t_1''=q|r_1'''\quad\implies\quad t=p_1''|(q|r_1''')\ \encircle{$PR_1$}$
    \item $(SINC):$ non possibile perch\'e $\overline{\beta}\neq\tau$
    \end{itemize}
  \end{itemize}
  In modo analogo \`e
  possibile vedere che se per lo stesso $\mu$ si ha
  $(p|q)|r\xrightarrow{\mu}t$ allora a seconda di che regole vengono
  usate, $t$ pu\`o essere in una delle forme riassunte nello schema
  seguente:
  \begin{itemize}
  \item $(PAR1):\quad (p|q)\xrightarrow{\mu}t'\quad\implies$ uno tra:
    \begin{itemize}
    \item $(PAR1):\quad p\xrightarrow{\mu}p'\quad\implies\quad t'=p'|q\quad\implies\quad t=(p'|q)|r\ \encircle{$P_2$}$
    \item $(PAR2):\quad q\xrightarrow{\mu}q'\implies t'=p|q'\quad\implies\quad t=(p|q')|r\ \encircle{$Q_2$}$
    \item $(SINC):\quad \mu=\tau,\ p\xrightarrow{\gamma}p_2'',\ q\xrightarrow{\overline{\gamma}}q_2''\quad\implies$\\
      \hbox{}\hfill$t'=p_2''|q_2''\quad\implies\quad t=(p_2''|q_2'')|r\ \encircle{$PQ_2$}$
    \end{itemize}
  \item $(PAR2):\quad r\xrightarrow{\mu}r'\quad\implies\quad t=(p|q)|r'\ \encircle{$R_2$}$
  \item $(SINC):\quad \mu=\tau,\ (p|q)\xrightarrow{\delta}t_2'',\ r\xrightarrow{\overline{\delta}}r_2''\quad\implies$ uno tra:
    \begin{itemize}
    \item $(PAR1):\quad p\xrightarrow{\delta}p_2'''\implies t_2''=p_2'''|q\quad\implies\quad t=(p_2'''|q)|r_2''\ \encircle{$PR_2$}$
    \item $(PAR2):\quad q\xrightarrow{\delta}q_2'''\implies t_2''=p|q_2'''\quad\implies\quad t=(p|q_2''')|r_2''\ \encircle{$QR_2$}$
    \item $(SINC):$ non possibile perch\'e $\delta\neq\tau$.
    \end{itemize}
  \end{itemize}
  Non è difficile vedere che ad esempio per il caso $(P_1)$
  vale che $p\xrightarrow{\mu}p'$ e $p|(q|r)\xrightarrow{\mu}p'(q|r)$
  e per il caso $(P_2)$ $p\xrightarrow{\mu}p'$ con stesso
  $\mu$ e quindi anche stesso $p'$ e
  $(p|q)|r\xrightarrow{\mu}(p'|q)|r$. $<p'|(q|r),\
  (p'|q)|r>\in R$ perch\'e $R$ contiene tutte le coppie nella forma
  $<p|(q|r),\ (p|q)|r>$, quindi per questo caso $R$ \`e chiusa per le
  transizioni. In modo analogo si può dimostrare i casi
  $(Q_1)$-$(Q_2)$ e quelli $(R_1)$-$(R_2)$. Per gli altri casi \`e necessario notare che ad
  esempio per il caso $(QR_1)$ si ha una sincronizzazione tra
  $q$ ed $r$, cos\`i come per il caso $(QR_2)$, questo
  significa che $\alpha$ e $\gamma$ coincidono, e quindi
  $q_1''=q_2'''$ e $r_1''=r_2''$. In modo analogo si dimostra che:
  $r_1''=r_2''=r_1'''$, $p_1''=p_2''=p_2'''$, $q_1'''=q_2''$. Quindi
  anche per i casi $(QR_1)$-$(QR_2)$,
  $(PQ_1)$-$(PQ_2)$ e
  $(PR_1)$-$(PR_2)$ vale che $R$ \`e chiusa per le
  transizioni.
\item \enbox{$p|nil=p$}: Si dimostra con il fatto che $R$ \`e chiusa per
  transizioni. L'unica regola della semantica applicabile a $p|nil$ è
  $(PAR1)$ quindi $p|nil\xrightarrow{\mu}p'|nil$ e
  $p\xrightarrow{\mu}p'$ e $<p'|nil,\ p'>\in R$.
\item \enbox{$p \backslash L = p\quad\text{ se }\mathcal{L}(p) \cap (L \cup
  \overline{L}) = \emptyset$}: Se $p\xrightarrow{\mu}p'$ allora per la
  regola $(RES)$ della semantica $p\backslash
  L\xrightarrow{\mu}p'\backslash L$ solo se $\mu,\overline{\mu}\not\in
  L$ equivalentemente se $\mu\not\in(L\cup\overline{L})$. Applicando
  la definizione 12.18 di sorta si evince che se
  $\mathcal{L}(p)\cap(L\cup\overline{L})=\emptyset$ significa che il
  processo $p$ non potr\`a mai fare un'azione di $L$ o una sua negata,
  quindi vale sempre che $p\backslash L\xrightarrow{\mu}p'\backslash L$,
  e la tesi vale perch\'e $<p'\backslash L,\ p'>\in R$ e dalla
  definizione di sorta se
  $\mathcal{L}(p)\cap(L\cup\overline{L})=\emptyset$ allora
  $\mathcal{L}(p')\cap(L\cup\overline{L})=\emptyset$.
\item \enbox{$p \backslash K \backslash L = p \backslash (K \cup L)$}: Se
  $p\backslash K\backslash L\xrightarrow{\mu}p'$ l'unica regola della
  semantica applicabile \`e $(RES)$ nel seguente modo:
  \begin{equation*}
    \inferrule*[right={$(\mu,\overline{\mu}\not\in L)$}]{
      \inferrule*[right={$(\mu,\overline{\mu}\not\in K)$}]{
        p\xrightarrow{\mu}p'
      }{
        p\backslash K\xrightarrow{\mu}p'\backslash K
      }
    }{
      p\backslash K\backslash L\xrightarrow{\mu}p'\backslash K\backslash L
    }    
  \end{equation*}
  Quindi $\mu,\overline{\mu}\not\in L$ e $\mu,\overline{\mu}\not\in
  K$. Equivalentemente $\mu,\overline{\mu}\not\in (K\cup L)$.

  Allo stesso modo per i termini $p\backslash(K\cup L)$ si pu\`o
  applicare
  \begin{equation*}
    \inferrule*[right={$(\mu,\overline{\mu}\not\in (K\cup L))$}]{
      p\xrightarrow{\mu}p'
    }{
      p\backslash(K\cup L)\xrightarrow{\mu}p'\backslash(K\cup L)
    }
  \end{equation*}
  e i $\mu$ per cui valgono sono gli stessi, inoltre $R$ \`e chiuso
  per le transizioni perch\'e $<p'\backslash K\backslash L,\
  p'\backslash(K\cup L)>\in R$.
\item \enbox{$p[f] \backslash L = p \backslash f^{-1} (L)[f]$}: Sul
  membro sinistro \`e possibile applicare solo:
  \begin{equation*}
    \inferrule*[right={$(\widehat f(\mu),\ \overline{\widehat f(\mu)}\ \not\in L)$}]{
      \inferrule*{
        p\xrightarrow{\mu}p'
      }{
        p[f]\xrightarrow{\widehat f(\mu)}p'[f]
      }
    }{
      p[f]\backslash L\xrightarrow{\widehat f(\mu)}p'[f]\backslash L
    }
  \end{equation*}
  su quello destro solo
  \begin{equation*}
    \inferrule*{
      \inferrule*[right={$(\mu,\ \overline{\mu}\ \not\in f^{-1}(L))$}]{
        p\xrightarrow{\mu}p'
      }{
        p\backslash f^{-1}(L)\xrightarrow{\mu}p'\backslash f^{-1}(L)
      }
    }{
      p\backslash f^{-1}(L)[f]\xrightarrow{\widehat f(\mu)}p'\backslash f^{-1}(L)[f]
    }
  \end{equation*}
  Si nota che poich\'e $L\subseteq\Lambda$ e $f:\Lambda\to\Lambda$ e
  per la definizione di $\widehat f$ vale che
  \begin{align*}
    (\mu,\ \overline{\mu}\ \not\in f^{-1}(L))&\implies (\widehat f(\mu),\ \widehat f(\overline{\mu})\ \not\in L)\\
    &\implies (\widehat f(\mu),\ \overline{\widehat f(\mu)}\ \not\in L)
  \end{align*}
  e quindi le condizioni dei due membri si equivalgono e
  $p[f]\backslash L\xrightarrow{\widehat f(\mu)}p'[f]\backslash L$ se e
  solo se $p\backslash f^{-1}(L)[f]\xrightarrow{\widehat
    f(\mu)}p'\backslash f^{-1}(L)[f]$. La tesi viene dal fatto che $R$
  \`e chiusa per transizioni perch\'e $<p'[f]\backslash L,\
  p'\backslash f^{-1}(L)[f]>\in R$.
\item \enbox{$(p|q) \backslash L = p \backslash L|q \backslash
    L\quad\text{ se }\mathcal{L}(p) \cap \overline{\mathcal{L}(q)}
    \cap (L \cup \overline L) = \emptyset$}: Per il membro sinistro si pu\`o
  applicare
  \begin{equation*}
    \inferrule*[right={$(\mu,\overline{\mu}\not\in L)$}]{
      p|q\xrightarrow{\mu}t'
    }{
      (p|q)\backslash L\xrightarrow{\mu}t
    }
  \end{equation*}
  e quindi si pu\`o applicare una delle regole del parallelismo per
  ottenere i possibili valori di $t'$ e $t$
  \begin{itemize}
  \item $(PAR1):\quad p\xrightarrow{\mu}p'\quad\implies\quad t'=p'|q\quad\implies\quad t=(p'|q)\backslash L$
  \item $(PAR2):\quad q\xrightarrow{\mu}q'\quad\implies\quad t'=p|q'\quad\implies\quad t=(p|q')\backslash L$
  \item $(SINC):\quad p\xrightarrow{\alpha}p'',\ q\xrightarrow{\overline{\alpha}}q''\implies t'=p''|q''\implies t=(p''|q'')\backslash L$
  \end{itemize}

  Per il membro destro si applica subito una delle regole del
  parallelismo e se $p\backslash L|q\backslash L\xrightarrow{\mu} t$ allora
  \begin{itemize}
  \item $(PAR1):\quad\frac{p\xrightarrow{\mu}p'}{p\backslash L\xrightarrow{\mu}p'\backslash L}(\mu,\overline\mu\not\in L)\quad\implies\quad t=p'\backslash L|q\backslash L$
  \item $(PAR2):\quad\frac{q\xrightarrow{\mu}q'}{q\backslash L\xrightarrow{\mu}q'\backslash L}(\mu,\overline\mu\not\in L)\quad\implies\quad t=p\backslash L|q'\backslash L$
  \item $(SINC):\quad\frac{p\xrightarrow{\alpha}p''}{p\backslash L\xrightarrow{\alpha}p''\backslash L}(\alpha,\overline\alpha\not\in L),\ \frac{q\xrightarrow{\alpha}q''}{q\backslash L\xrightarrow{\alpha}q''\backslash L}(\overline\alpha,\alpha\not\in L)\quad\implies$\\
    \hbox{}\hfill$t=p''\backslash L|q''\backslash L$
  \end{itemize}
  
  La regola \`e quasi verificata perch\'e $R$ sarebbe chiusa per tutte
  le transizioni se non fosse per le condizioni aggiuntive imposte sul
  membro destro nella sincronizzazione. Tali condizioni impediscono a
  $p$ e $q$ di sincronizzarsi su $\alpha$ quando questi o il suo
  complementare appartengono ad $L$, ma questa condizione \`e coperta da
  quella pi\`u forte imposta nella regola: $\mathcal{L}(p) \cap \overline{\mathcal{L}(q)}
    \cap (L \cup \overline L) = \emptyset$. Infatti per la definizione
    di sorta, questa impone che nei processi $p$ e $q$ non compaiano
    mai coppie di processi complementari contenuti in $L$.
\item \enbox{$p[Id] = p$}: \`E possibile applicare
  \begin{equation*}
    \inferrule*{
      p\xrightarrow{\mu}p'
    }{
      p[Id]\xrightarrow{\widehat{Id}(\mu)}p'[Id]
    }
  \end{equation*}
  e per la definizione di $\widehat f$ e $Id$, si ha che
  $\widehat{Id}(\mu)=Id(\mu)=\mu$ quindi $p[Id]\xrightarrow{\mu}p'[Id]$ se e
  solo se $p\xrightarrow{\mu}p'$. $R$ \`e chiusa per
  transizioni perch\'e $<p'[Id],\ p'>\in R$.
\item \enbox{$p[f] = p[f']\quad\text{ se }f
    \upharpoonright_{\mathcal{L}(p)} =
    f'\upharpoonright_{\mathcal{L}(p)}$}: Si pu\`o applicare $(REL)$
  al membro sinistro e a quello destro:
  \begin{equation*}
    \inferrule*{
      p\xrightarrow{\mu}p'
    }{
      p[f]\xrightarrow{\widehat f(\mu)}p'[f]
    }
  \end{equation*}
  \begin{equation*}
    \inferrule*{
      p\xrightarrow{\mu}p'
    }{
      p[f']\xrightarrow{\widehat{f'}(\mu)}p'[f']
    }
  \end{equation*}
  Si nota facilmente che se $\widehat f=\widehat{f'}$ allora $p[f]$ e
  $p[f']$ hanno le stesse $\mu$-derivate. La condizione imposta nella
  regola indica che la restrizione di $f$ su tutte le possibili azioni
  di $p$ deve essere uguale alla restrizione di $f'$ su tutte le
  possibili azioni di $p$, e quindi per ogni possibile $\mu$ vale che
  $f(\mu)=f'(\mu)$ e quindi $\widehat f(\mu)=\widehat{f'}(\mu)$.
\item \enbox{$p[f][f'] = p[f' \circ f]$}: Per il membro sinistro si
  pu\`o applicare $(REL)$ due volte:
  \begin{equation*}
    \inferrule*{
      \inferrule*{
        p\xrightarrow{\mu}p'
      }{
        p[f]\xrightarrow{\widehat f(\mu)}p'[f]
      }
    }{
      p[f][f']\xrightarrow{\widehat{f'}(\widehat f(\mu))}p'[f][f']
    }
  \end{equation*}
  Per il membro destro si pu\`o applicare $(REL)$ una volta
  \begin{equation*}
    \inferrule*{
      p\xrightarrow{\mu}p'
    }{
      p[f'\circ f]\xrightarrow{\widehat{(f'\circ f)}(\mu)}p'[f'\circ f]
    }
  \end{equation*}
  Dalla definizione di $\widehat f$ e di funzione composta si verifica
  facilmente che $\widehat{(f'\circ f)}(\mu)=\widehat{f'}(\widehat
  f(\mu))$. Quindi $R$ \`e chiusa per transizioni.
\item \enbox{$(p|q)[f] = p[f]|q[f]\quad\text{ se }f
    \upharpoonright_{(L \cup \overline{L})}\text{ è biunivoca, dove }L
    = \mathcal{L}(p) \cup \mathcal{L}(q)$}: Per il membro sinistro si
  pu\`o applicare $(REL)$:
  \begin{equation*}
    \inferrule*{
      p|q\xrightarrow{\mu}t'
    }{
      (p|q)[f]\xrightarrow{\widehat f(\mu)}t
    }
  \end{equation*}
  e per valutare i valori di $t'$ e $t$ \`e necessario vedere quale
  regole del parallelismo sono usate:
  \begin{itemize}
  \item $(PAR1):\quad p\xrightarrow{\mu}p'\quad\implies\quad t'=p'|q\quad\implies\quad t=(p'|q)[f]$
  \item $(PAR2):\quad q\xrightarrow{\mu}q'\quad\implies\quad t'=p|q'\quad\implies\quad t=(p|q')[f]$
  \item $(PAR1):\quad \mu=\tau,\ p\xrightarrow{\alpha}p'',\ q\xrightarrow{\overline\alpha}q''\quad\implies$\\
    \hbox{}\hfill$t'=p''|q''\quad\implies\quad t=(p''|q'')[f]$
  \end{itemize}
  
  Per il membro destro si possono applicare subito le regole per il
  parallelo:
  \begin{align*}
    (PAR1):\qquad&\inferrule*{
      \inferrule*{
        p\xrightarrow{\mu}p'
      }{
        p[f]\xrightarrow{\widehat f(\mu)}p'[f]
      }
    }{
      p[f]|q[f]\xrightarrow{\widehat f(\mu)}p'[f]|q[f]
    }\\\\
    (PAR2):\qquad&\inferrule*{
      \inferrule*{
        q\xrightarrow{\mu}q'
      }{
        q[f]\xrightarrow{\widehat f(\mu)}q'[f]
      }
    }{
      p[f]|q[f]\xrightarrow{\widehat f(\mu)}p[f]|q'[f]
    }\\\\
    (SINC):\qquad&\inferrule*[right={$(\widehat f(\beta)=\overline{\widehat f(\gamma)})$}]{
      \inferrule*{
        p\xrightarrow{\beta}p'''
      }{
        p[f]\xrightarrow{\widehat f(\beta)}p'''[f]
      }\qquad
      \inferrule*{
        q\xrightarrow{\gamma}q'''
      }{
        q[f]\xrightarrow{\widehat f(\gamma)}q'''[f]
      }
    }{
      p[f]|q[f]\xrightarrow{\tau=\widehat f(\tau)}p'''[f]|q'''[f]
    }
  \end{align*}
  la condizione di \emph{biunivocit\`a} (limitatamente a tutte le
  possibili azioni che possono fare $p$ e $q$) imposta ad $f$
  garantisce che se $\widehat f(\beta)=\overline{\widehat
    f(\gamma)}=\widehat f(\overline\gamma)$ allora
  $\beta=\overline\gamma$ e quindi $p$ e $q$ si possono sincronizzare
  solo sugli stessi $\alpha$ e $\overline\alpha$ visti per il membro
  sinistro, e quindi $p''=p'''$ e $q''=q'''$.
  
  Detto questo allora $R$ \`e chiusa per le transizioni e quindi la
  legge vale.
\end{enumerate}

\sectionline
\section*{\hyperref[toc]{Esercizio 12.2}}
\addcontentsline{toc}{section}{\protect\numberline{}Esercizio 12.2}
\subsection*{Testo:}
Mostrare che la legge seguente
$$
(\tau 4)\qquad p + \tau.(p + q) = \tau.(p + q)
$$
è derivabile dall’insieme $E_4$ definito in Tabella~12.9.

\subsection*{Soluzione:}
Si ha che:
\begin{align*}
  p + \tau.(p + q) &= p+((p+q)+\tau.(p+q)) & \text{ da } (\tau 2)\\
  &= (p+(p+q))+\tau.(p+q) & \text{ da } (A2)\\
  &= ((p+p)+q)+\tau.(p+q) & \text{ da } (A2)\\
  &= (p+q)+\tau.(p+q) & \text{ da } (A4)\\
  &= \tau.(p+q) & \text{ da } (\tau 2)
\end{align*}
quindi vale che $E_4\vdash p + \tau.(p + q) = \tau.(p + q)$.
 
\sectionline
\end{document}

